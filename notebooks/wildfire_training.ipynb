{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sTqGHXP2JL7q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# CONFIG\n",
        "# ==============================================================#\n",
        "DATA_PATH = \"/content/drive/MyDrive/Colab Notebooks/filename.csv\"\n",
        "SAVE_DIR = \"/content/drive/MyDrive/Colab Notebooks/result/\"\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 250\n",
        "LR = 1e-3\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "dF2s2NvqJkaE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# FEATURE ENGINEERING FUNCTIONS\n",
        "# ==============================================================#\n",
        "def compute_simple_fwi(df):\n",
        "    tmp = df[['avgtemp_c','avg_humidity','wind_kph','total_precip_mm']].copy()\n",
        "    for c in tmp.columns:\n",
        "        mn, mx = tmp[c].min(), tmp[c].max()\n",
        "        if mx - mn <= 0:\n",
        "            tmp[c] = 0.5\n",
        "        else:\n",
        "            tmp[c] = (tmp[c] - mn) / (mx - mn)\n",
        "    fwi = 0.45 * tmp['avgtemp_c'] + 0.3 * (1 - tmp['avg_humidity']) + 0.2 * tmp['wind_kph'] - 0.05 * tmp['total_precip_mm']\n",
        "    return fwi.clip(0, 1)"
      ],
      "metadata": {
        "id": "jlPhEZ1hKA2V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# DATA PREPROCESSING\n",
        "# ==============================================================#\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "df['acq_date'] = pd.to_datetime(df['acq_date'])\n",
        "df = df.sort_values('acq_date')\n",
        "\n",
        "# Group by spatial cell (rounded lat/lon)\n",
        "df['lat_r'] = df['latitude'].round(3)\n",
        "df['lon_r'] = df['longitude'].round(3)\n",
        "df['cell_id'] = df['lat_r'].astype(str) + \"_\" + df['lon_r'].astype(str)\n",
        "\n",
        "# Compute derived features\n",
        "df['fwi_simple'] = compute_simple_fwi(df)\n",
        "df['dayofyear'] = df['acq_date'].dt.dayofyear\n",
        "df['hour'] = df['acq_date'].dt.hour\n",
        "df = df.sort_values(['cell_id','acq_date'])\n",
        "\n",
        "# Rolling mean features per cell\n",
        "df[['temp_roll3','precip_roll3','hum_roll3','wind_roll3']] = df.groupby('cell_id')[['avgtemp_c','total_precip_mm','avg_humidity','wind_kph']].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "# Drop missing rows\n",
        "df = df.dropna(subset=['avgtemp_c','total_precip_mm','avg_humidity','wind_kph','fwi_simple'])\n",
        "\n",
        "# Target\n",
        "df['risk_now'] = df['fwi_simple']  # immediate risk\n",
        "FEATURE_COLS = ['avgtemp_c','total_precip_mm','avg_humidity','pressure_in','wind_kph',\n",
        "                'fwi_simple','temp_roll3','precip_roll3','hum_roll3','wind_roll3','dayofyear','hour']"
      ],
      "metadata": {
        "id": "UlpfCZyLKCXV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df[FEATURE_COLS].shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aslNMKdwKx0Q",
        "outputId": "69755d33-43c8-4559-b816-ebabdddad884"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18191, 19)\n",
            "(18191, 12)\n",
            "      latitude  longitude   acq_date  avgtemp_c  total_precip_mm  \\\n",
            "259    10.1522    76.3808 2024-10-24       26.2            22.81   \n",
            "802    10.1519    76.3924 2024-10-29       26.9             0.60   \n",
            "262    10.1801    77.8067 2024-10-24       22.9             2.02   \n",
            "4334   10.4378    78.0548 2024-11-09       24.6             0.10   \n",
            "4338   10.4395    78.0435 2024-11-09       24.6             0.10   \n",
            "\n",
            "      avg_humidity  pressure_in  wind_kph   lat_r   lon_r        cell_id  \\\n",
            "259           85.0    29.837917      17.6  10.152  76.381  10.152_76.381   \n",
            "802           76.0    29.807917      14.8  10.152  76.392  10.152_76.392   \n",
            "262           86.0    29.862083       6.8  10.180  77.807   10.18_77.807   \n",
            "4334          79.0    29.862500      11.2  10.438  78.055  10.438_78.055   \n",
            "4338          79.0    29.862500      11.2  10.440  78.044   10.44_78.044   \n",
            "\n",
            "      fwi_simple  dayofyear  hour  temp_roll3  precip_roll3  hum_roll3  \\\n",
            "259     0.463314        298     0        26.2         22.81       85.0   \n",
            "802     0.526795        303     0        26.9          0.60       76.0   \n",
            "262     0.374753        298     0        22.9          2.02       86.0   \n",
            "4334    0.459893        314     0        24.6          0.10       79.0   \n",
            "4338    0.459893        314     0        24.6          0.10       79.0   \n",
            "\n",
            "      wind_roll3  risk_now  \n",
            "259         17.6  0.463314  \n",
            "802         14.8  0.526795  \n",
            "262          6.8  0.374753  \n",
            "4334        11.2  0.459893  \n",
            "4338        11.2  0.459893  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# FEATURE SCALING\n",
        "# ==============================================================#\n",
        "scaler = StandardScaler()\n",
        "df[FEATURE_COLS] = scaler.fit_transform(df[FEATURE_COLS])\n",
        "joblib.dump({'scaler': scaler}, os.path.join(SAVE_DIR, \"scaler.pkl\"))\n",
        "print(\"✅ StandardScaler fitted and saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kvsy3HCKcAI",
        "outputId": "17b4bdff-eb2c-4320-ffa1-48e3b0921a9d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ StandardScaler fitted and saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# DATASET CLASS\n",
        "# ==============================================================#\n",
        "class WildfireDataset(Dataset):\n",
        "    def __init__(self, df, feature_cols):\n",
        "        self.X = df[feature_cols].values.astype(np.float32)\n",
        "        self.y = df['risk_now'].values.astype(np.float32)\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "X9mbL8XjN_ue"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# SPLIT DATA (BY TIME)\n",
        "# ==============================================================#\n",
        "t1 = df['acq_date'].quantile(0.7)\n",
        "t2 = df['acq_date'].quantile(0.85)\n",
        "train_df = df[df['acq_date'] <= t1]\n",
        "val_df   = df[(df['acq_date'] > t1) & (df['acq_date'] <= t2)]\n",
        "test_df  = df[df['acq_date'] > t2]\n",
        "\n",
        "train_ds = WildfireDataset(train_df, FEATURE_COLS)\n",
        "val_ds   = WildfireDataset(val_df, FEATURE_COLS)\n",
        "test_ds  = WildfireDataset(test_df, FEATURE_COLS)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(f\"Data points — Train: {len(train_ds)}, Val: {len(val_ds)}, Test: {len(test_ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGMjYigEQXWX",
        "outputId": "fc6c716a-d86c-4e2a-acea-f52392417031"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data points — Train: 12958, Val: 2948, Test: 2285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# MODEL DEFINITION\n",
        "# ==============================================================#\n",
        "class RiskModel(nn.Module):\n",
        "    def __init__(self, n_features, hidden=128, layers=2, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(n_features, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, hidden//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden//2, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.fc(x)).squeeze(1)"
      ],
      "metadata": {
        "id": "YoLeHQOkRLIU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# TRAINING\n",
        "# ==============================================================#\n",
        "model = RiskModel(len(FEATURE_COLS)).to(DEVICE)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, factor=0.5)\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "best_val = float('inf')\n",
        "for epoch in range(EPOCHS):\n",
        "    # Train\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    y_train_true, y_train_pred = [], []\n",
        "    for X, y in train_loader:\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "        preds = model(X)\n",
        "        loss = criterion(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_losses.append(loss.item())\n",
        "        y_train_true += y.cpu().tolist()\n",
        "        y_train_pred += preds.detach().cpu().tolist()\n",
        "\n",
        "    # Validate\n",
        "    model.eval()\n",
        "    val_losses = []\n",
        "    y_val_true, y_val_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in val_loader:\n",
        "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "            preds = model(X)\n",
        "            loss = criterion(preds, y)\n",
        "            val_losses.append(loss.item())\n",
        "            y_val_true += y.cpu().tolist()\n",
        "            y_val_pred += preds.cpu().tolist()\n",
        "\n",
        "    # Compute metrics\n",
        "    mean_train, mean_val = np.mean(train_losses), np.mean(val_losses)\n",
        "    rmse_train = math.sqrt(mean_squared_error(y_train_true, y_train_pred))\n",
        "    mae_train = mean_absolute_error(y_train_true, y_train_pred)\n",
        "    r2_train = r2_score(y_train_true, y_train_pred)\n",
        "\n",
        "    rmse_val = math.sqrt(mean_squared_error(y_val_true, y_val_pred))\n",
        "    mae_val = mean_absolute_error(y_val_true, y_val_pred)\n",
        "    r2_val = r2_score(y_val_true, y_val_pred)\n",
        "\n",
        "    scheduler.step(mean_val)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss={mean_train:.5f}, RMSE={rmse_train:.4f}, MAE={mae_train:.4f} \"\n",
        "          f\"| Val Loss={mean_val:.5f}, RMSE={rmse_val:.4f}, MAE={mae_val:.4f}\")\n",
        "\n",
        "    if mean_val < best_val:\n",
        "        best_val = mean_val\n",
        "        torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"best_model.pth\"))\n",
        "        print(f\"💾 Saved best model (Val Loss={best_val:.5f})\")\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(SAVE_DIR, \"epoch250_model.pth\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVeEqEK9RRJh",
        "outputId": "547766d7-942f-4090-dcfb-d498d2642102"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250 | Train Loss=0.00063, RMSE=0.0252, MAE=0.0160 | Val Loss=0.00009, RMSE=0.0086, MAE=0.0069\n",
            "💾 Saved best model (Val Loss=0.00009)\n",
            "Epoch 2/250 | Train Loss=0.00019, RMSE=0.0138, MAE=0.0099 | Val Loss=0.00003, RMSE=0.0058, MAE=0.0044\n",
            "💾 Saved best model (Val Loss=0.00003)\n",
            "Epoch 3/250 | Train Loss=0.00015, RMSE=0.0123, MAE=0.0086 | Val Loss=0.00006, RMSE=0.0071, MAE=0.0053\n",
            "Epoch 4/250 | Train Loss=0.00013, RMSE=0.0113, MAE=0.0080 | Val Loss=0.00005, RMSE=0.0064, MAE=0.0047\n",
            "Epoch 5/250 | Train Loss=0.00012, RMSE=0.0107, MAE=0.0075 | Val Loss=0.00002, RMSE=0.0044, MAE=0.0032\n",
            "💾 Saved best model (Val Loss=0.00002)\n",
            "Epoch 6/250 | Train Loss=0.00011, RMSE=0.0104, MAE=0.0072 | Val Loss=0.00002, RMSE=0.0045, MAE=0.0035\n",
            "Epoch 7/250 | Train Loss=0.00010, RMSE=0.0101, MAE=0.0070 | Val Loss=0.00001, RMSE=0.0037, MAE=0.0029\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 8/250 | Train Loss=0.00009, RMSE=0.0097, MAE=0.0068 | Val Loss=0.00003, RMSE=0.0049, MAE=0.0036\n",
            "Epoch 9/250 | Train Loss=0.00009, RMSE=0.0095, MAE=0.0065 | Val Loss=0.00001, RMSE=0.0036, MAE=0.0027\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 10/250 | Train Loss=0.00009, RMSE=0.0095, MAE=0.0065 | Val Loss=0.00001, RMSE=0.0034, MAE=0.0024\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 11/250 | Train Loss=0.00008, RMSE=0.0091, MAE=0.0062 | Val Loss=0.00004, RMSE=0.0056, MAE=0.0038\n",
            "Epoch 12/250 | Train Loss=0.00008, RMSE=0.0092, MAE=0.0062 | Val Loss=0.00001, RMSE=0.0029, MAE=0.0021\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 13/250 | Train Loss=0.00008, RMSE=0.0089, MAE=0.0060 | Val Loss=0.00001, RMSE=0.0030, MAE=0.0025\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 14/250 | Train Loss=0.00007, RMSE=0.0086, MAE=0.0058 | Val Loss=0.00001, RMSE=0.0036, MAE=0.0025\n",
            "Epoch 15/250 | Train Loss=0.00007, RMSE=0.0087, MAE=0.0058 | Val Loss=0.00001, RMSE=0.0035, MAE=0.0026\n",
            "Epoch 16/250 | Train Loss=0.00007, RMSE=0.0085, MAE=0.0058 | Val Loss=0.00002, RMSE=0.0040, MAE=0.0029\n",
            "Epoch 17/250 | Train Loss=0.00007, RMSE=0.0085, MAE=0.0058 | Val Loss=0.00001, RMSE=0.0028, MAE=0.0019\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 18/250 | Train Loss=0.00008, RMSE=0.0088, MAE=0.0058 | Val Loss=0.00003, RMSE=0.0050, MAE=0.0034\n",
            "Epoch 19/250 | Train Loss=0.00007, RMSE=0.0085, MAE=0.0057 | Val Loss=0.00001, RMSE=0.0028, MAE=0.0020\n",
            "💾 Saved best model (Val Loss=0.00001)\n",
            "Epoch 20/250 | Train Loss=0.00007, RMSE=0.0083, MAE=0.0056 | Val Loss=0.00002, RMSE=0.0042, MAE=0.0024\n",
            "Epoch 21/250 | Train Loss=0.00007, RMSE=0.0085, MAE=0.0057 | Val Loss=0.00001, RMSE=0.0030, MAE=0.0019\n",
            "Epoch 22/250 | Train Loss=0.00007, RMSE=0.0085, MAE=0.0056 | Val Loss=0.00001, RMSE=0.0032, MAE=0.0022\n",
            "Epoch 23/250 | Train Loss=0.00007, RMSE=0.0086, MAE=0.0057 | Val Loss=0.00003, RMSE=0.0047, MAE=0.0035\n",
            "Epoch 24/250 | Train Loss=0.00006, RMSE=0.0080, MAE=0.0053 | Val Loss=0.00000, RMSE=0.0022, MAE=0.0014\n",
            "💾 Saved best model (Val Loss=0.00000)\n",
            "Epoch 25/250 | Train Loss=0.00006, RMSE=0.0079, MAE=0.0053 | Val Loss=0.00001, RMSE=0.0023, MAE=0.0014\n",
            "Epoch 26/250 | Train Loss=0.00006, RMSE=0.0078, MAE=0.0052 | Val Loss=0.00001, RMSE=0.0024, MAE=0.0016\n",
            "Epoch 27/250 | Train Loss=0.00006, RMSE=0.0079, MAE=0.0053 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0012\n",
            "💾 Saved best model (Val Loss=0.00000)\n",
            "Epoch 28/250 | Train Loss=0.00006, RMSE=0.0079, MAE=0.0053 | Val Loss=0.00000, RMSE=0.0021, MAE=0.0013\n",
            "Epoch 29/250 | Train Loss=0.00006, RMSE=0.0077, MAE=0.0052 | Val Loss=0.00001, RMSE=0.0029, MAE=0.0021\n",
            "Epoch 30/250 | Train Loss=0.00006, RMSE=0.0080, MAE=0.0052 | Val Loss=0.00000, RMSE=0.0021, MAE=0.0015\n",
            "Epoch 31/250 | Train Loss=0.00006, RMSE=0.0078, MAE=0.0052 | Val Loss=0.00001, RMSE=0.0029, MAE=0.0021\n",
            "Epoch 32/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0051 | Val Loss=0.00001, RMSE=0.0023, MAE=0.0013\n",
            "Epoch 33/250 | Train Loss=0.00006, RMSE=0.0077, MAE=0.0051 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0013\n",
            "Epoch 34/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0051 | Val Loss=0.00002, RMSE=0.0031, MAE=0.0017\n",
            "Epoch 35/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0051 | Val Loss=0.00001, RMSE=0.0028, MAE=0.0021\n",
            "Epoch 36/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00001, RMSE=0.0025, MAE=0.0015\n",
            "Epoch 37/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00001, RMSE=0.0025, MAE=0.0016\n",
            "Epoch 38/250 | Train Loss=0.00006, RMSE=0.0078, MAE=0.0051 | Val Loss=0.00001, RMSE=0.0027, MAE=0.0016\n",
            "Epoch 39/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 40/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0028, MAE=0.0017\n",
            "Epoch 41/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0020, MAE=0.0011\n",
            "Epoch 42/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0011\n",
            "Epoch 43/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0011\n",
            "Epoch 44/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00001, RMSE=0.0022, MAE=0.0012\n",
            "Epoch 45/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0011\n",
            "Epoch 46/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00001, RMSE=0.0021, MAE=0.0011\n",
            "Epoch 47/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0021, MAE=0.0012\n",
            "Epoch 48/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 49/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00001, RMSE=0.0021, MAE=0.0011\n",
            "Epoch 50/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0051 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 51/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00001, RMSE=0.0023, MAE=0.0013\n",
            "Epoch 52/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 53/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 54/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0020, MAE=0.0011\n",
            "Epoch 55/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0021, MAE=0.0011\n",
            "Epoch 56/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 57/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 58/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00001, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 59/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 60/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 61/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 62/250 | Train Loss=0.00006, RMSE=0.0077, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 63/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 64/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 65/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 66/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0019, MAE=0.0010\n",
            "Epoch 67/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 68/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 69/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 70/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 71/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 72/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 73/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 74/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 75/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 76/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 77/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 78/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 79/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 80/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 81/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 82/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 83/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 84/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 85/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 86/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 87/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 88/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 89/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 90/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 91/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 92/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 93/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 94/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 95/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 96/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 97/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 98/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 99/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 100/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 101/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 102/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 103/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 104/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 105/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 106/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 107/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 108/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 109/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 110/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 111/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 112/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 113/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 114/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 115/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 116/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 117/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 118/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 119/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 120/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 121/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 122/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 123/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 124/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 125/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 126/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 127/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 128/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 129/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 130/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 131/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 132/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 133/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 134/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 135/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 136/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 137/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 138/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 139/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 140/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 141/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 142/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 143/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 144/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 145/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 146/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 147/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 148/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 149/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 150/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 151/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 152/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 153/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 154/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 155/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 156/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 157/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 158/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 159/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 160/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 161/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 162/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 163/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 164/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 165/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 166/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 167/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 168/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 169/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 170/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 171/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 172/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 173/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 174/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 175/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 176/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 177/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 178/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 179/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 180/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 181/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 182/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 183/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 184/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 185/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 186/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 187/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 188/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 189/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 190/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 191/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 192/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 193/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 194/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 195/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 196/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 197/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 198/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 199/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 200/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 201/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 202/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 203/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 204/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 205/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 206/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 207/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 208/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 209/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 210/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 211/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 212/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 213/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 214/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 215/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 216/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 217/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 218/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 219/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 220/250 | Train Loss=0.00006, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 221/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 222/250 | Train Loss=0.00006, RMSE=0.0076, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 223/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 224/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 225/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 226/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 227/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 228/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 229/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 230/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 231/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 232/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 233/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 234/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 235/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 236/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 237/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 238/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 239/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 240/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 241/250 | Train Loss=0.00005, RMSE=0.0073, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 242/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 243/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 244/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 245/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 246/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0050 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 247/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 248/250 | Train Loss=0.00006, RMSE=0.0075, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 249/250 | Train Loss=0.00005, RMSE=0.0072, MAE=0.0048 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n",
            "Epoch 250/250 | Train Loss=0.00005, RMSE=0.0074, MAE=0.0049 | Val Loss=0.00000, RMSE=0.0020, MAE=0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# TEST EVALUATION\n",
        "# ==============================================================#\n",
        "model.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"best_model.pth\")))\n",
        "model.eval()\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "with torch.no_grad():\n",
        "    for X, y in test_loader:\n",
        "        X, y = X.to(DEVICE), y.to(DEVICE)\n",
        "        preds = model(X)\n",
        "        y_true += y.cpu().tolist()\n",
        "        y_pred += preds.cpu().tolist()\n",
        "\n",
        "rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "print(f\"Test: RMSE={rmse:.4f}, MAE={mae:.4f}\")\n",
        "print(\"✅ Training complete. Model and scaler saved in:\", SAVE_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqAr8WUJSmRv",
        "outputId": "02f0d5bc-4f8c-48a9-b3a1-bc80ada1a91e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: RMSE=0.0035, MAE=0.0025\n",
            "✅ Training complete. Model and scaler saved in: /content/drive/MyDrive/Colab Notebooks/result/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import folium\n",
        "from folium.plugins import HeatMap"
      ],
      "metadata": {
        "id": "pzxjKHXeUqaD"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# CONFIG\n",
        "# ==============================================================#\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Colab Notebooks/result/\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "FEATURE_COLS = ['avgtemp_c','total_precip_mm','avg_humidity','pressure_in','wind_kph',\n",
        "                'fwi_simple','temp_roll3','precip_roll3','hum_roll3','wind_roll3','dayofyear','hour']"
      ],
      "metadata": {
        "id": "NTeNfms_Urxv"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# UTILITIES\n",
        "# ==============================================================#\n",
        "def compute_simple_fwi(df):\n",
        "    tmp = df[['avgtemp_c','avg_humidity','wind_kph','total_precip_mm']].copy()\n",
        "    for c in tmp.columns:\n",
        "        mn, mx = tmp[c].min(), tmp[c].max()\n",
        "        if mx - mn <= 0:\n",
        "            tmp[c] = 0.5\n",
        "        else:\n",
        "            tmp[c] = (tmp[c] - mn) / (mx - mn)\n",
        "    fwi = 0.45 * tmp['avgtemp_c'] + 0.3 * (1 - tmp['avg_humidity']) + 0.2 * tmp['wind_kph'] - 0.05 * tmp['total_precip_mm']\n",
        "    return fwi.clip(0, 1)\n",
        "\n",
        "class RiskModel(nn.Module):\n",
        "    def __init__(self, n_features, hidden=128, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(n_features, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, hidden//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden//2, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.fc(x)).squeeze(1)"
      ],
      "metadata": {
        "id": "JfOU4C3dU5AD"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# LOAD MODEL + SCALER\n",
        "# ==============================================================#\n",
        "scaler = joblib.load(os.path.join(MODEL_DIR, \"scaler.pkl\"))['scaler']\n",
        "model = RiskModel(len(FEATURE_COLS))\n",
        "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"best_model.pth\"), map_location=DEVICE))\n",
        "model.to(DEVICE).eval()\n",
        "print(\"✅ Model and scaler loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4q32Af-U6r6",
        "outputId": "aca88117-f66e-4fcb-889f-106ad8ae657d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and scaler loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# INFERENCE FUNCTION\n",
        "# ==============================================================#\n",
        "def predict_fire_risk(df):\n",
        "    \"\"\"Predicts immediate fire risk for one or more rows in a DataFrame.\"\"\"\n",
        "    df = df.copy()\n",
        "    df['fwi_simple'] = compute_simple_fwi(df)\n",
        "    df['dayofyear'] = df['acq_date'].dt.dayofyear\n",
        "    df['hour'] = df['acq_date'].dt.hour\n",
        "    df[['temp_roll3','precip_roll3','hum_roll3','wind_roll3']] = df[['avgtemp_c','total_precip_mm','avg_humidity','wind_kph']].rolling(3, min_periods=1).mean()\n",
        "\n",
        "    df[FEATURE_COLS] = scaler.transform(df[FEATURE_COLS])\n",
        "    X = torch.tensor(df[FEATURE_COLS].values, dtype=torch.float32).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        preds = model(X).cpu().numpy()\n",
        "    return preds\n"
      ],
      "metadata": {
        "id": "EyO625WiVNjW"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# HEATMAP GENERATION\n",
        "# ==============================================================#\n",
        "def generate_heatmap(data, output_html=None):\n",
        "    \"\"\"Creates a folium heatmap from DataFrame with columns [latitude, longitude, risk].\"\"\"\n",
        "    if output_html is None:\n",
        "        output_html = os.path.join(MODEL_DIR, \"wildfire_heatmap.html\")\n",
        "\n",
        "    center = [data['latitude'].mean(), data['longitude'].mean()]\n",
        "    m = folium.Map(location=center, zoom_start=6)\n",
        "    heat_data = data[['latitude','longitude','risk']].values.tolist()\n",
        "    HeatMap(heat_data, radius=10, blur=15, max_zoom=10).add_to(m)\n",
        "    m.save(output_html)\n",
        "    print(\"✅ Heatmap saved to:\", output_html)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T1AGCwtsVVVj"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# EXAMPLE USAGE\n",
        "# ==============================================================#\n",
        "if __name__ == \"__main__\":\n",
        "    # Example input: one row or multiple rows\n",
        "    example = pd.DataFrame({\n",
        "        'latitude':[11.77],\n",
        "        'longitude':[-76.46],\n",
        "        'acq_date': pd.to_datetime([\"2019-02-21 12:00\"]),\n",
        "        'avgtemp_c': np.random.uniform(35),\n",
        "        'total_precip_mm': np.random.uniform(0),\n",
        "        'avg_humidity': np.random.uniform(93),\n",
        "        'pressure_in': np.random.uniform(29.5),\n",
        "        'wind_kph': np.random.uniform(20.3)\n",
        "    })\n",
        "\n",
        "    risks = predict_fire_risk(example)\n",
        "    example['risk'] = risks\n",
        "    print(\"🔥 Predicted risks:\\n\", example[['latitude','longitude','risk']])\n",
        "\n",
        "    # Save heatmap in the model directory\n",
        "    heatmap_path = os.path.join(MODEL_DIR, \"wildfire_heatmap.html\")\n",
        "    generate_heatmap(example, output_html=heatmap_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVyX9-QBWDOF",
        "outputId": "08a7e437-e977-42d1-de2e-a5b9d66cbcb6"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 Predicted risks:\n",
            "    latitude  longitude      risk\n",
            "0     11.77     -76.46  0.482213\n",
            "✅ Heatmap saved to: /content/drive/MyDrive/Colab Notebooks/result/wildfire_heatmap.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "from datetime import datetime, timedelta"
      ],
      "metadata": {
        "id": "7znLnZXSYURA"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# CONFIG\n",
        "# ==============================================================#\n",
        "MODEL_DIR = \"/content/drive/MyDrive/Colab Notebooks/result/\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "FEATURE_COLS = ['avgtemp_c','total_precip_mm','avg_humidity','pressure_in','wind_kph',\n",
        "                'fwi_simple','temp_roll3','precip_roll3','hum_roll3','wind_roll3','dayofyear','hour']"
      ],
      "metadata": {
        "id": "8gJsINOsYVbL"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# UTILITIES\n",
        "# ==============================================================#\n",
        "def compute_simple_fwi(row):\n",
        "    \"\"\"Compute simplified FWI for a single row (Series).\"\"\"\n",
        "    t = row['avgtemp_c']/50  # normalize temperature roughly\n",
        "    h = 1 - row['avg_humidity']/100\n",
        "    w = row['wind_kph']/100\n",
        "    p = row['total_precip_mm']/100\n",
        "    fwi = 0.45*t + 0.3*h + 0.2*w - 0.05*p\n",
        "    return np.clip(fwi, 0, 1)\n",
        "\n",
        "class RiskModel(nn.Module):\n",
        "    def __init__(self, n_features, hidden=128, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(n_features, hidden),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, hidden//2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden//2, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.fc(x)).squeeze(1)"
      ],
      "metadata": {
        "id": "V4ueeHysYbo9"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# LOAD MODEL + SCALER\n",
        "# ==============================================================#\n",
        "scaler = joblib.load(os.path.join(MODEL_DIR, \"scaler.pkl\"))['scaler']\n",
        "model = RiskModel(len(FEATURE_COLS))\n",
        "model.load_state_dict(torch.load(os.path.join(MODEL_DIR, \"best_model.pth\"), map_location=DEVICE))\n",
        "model.to(DEVICE).eval()\n",
        "print(\"✅ Model and scaler loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut_Ix6NAYhHt",
        "outputId": "30fc0346-6d99-4244-9549-c348b5442cdd"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model and scaler loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# PREDICTION FUNCTION\n",
        "# ==============================================================#\n",
        "def predict_risk_row(row):\n",
        "    \"\"\"Predict wildfire risk for a single row of weather data.\"\"\"\n",
        "    df = pd.DataFrame([row])\n",
        "    df['fwi_simple'] = compute_simple_fwi(df.iloc[0])\n",
        "    df['dayofyear'] = df['acq_date'].dt.dayofyear\n",
        "    df['hour'] = df['acq_date'].dt.hour\n",
        "    df[['temp_roll3','precip_roll3','hum_roll3','wind_roll3']] = df[['avgtemp_c','total_precip_mm','avg_humidity','wind_kph']].rolling(1).mean()\n",
        "    X = scaler.transform(df[FEATURE_COLS])\n",
        "    X = torch.tensor(X, dtype=torch.float32).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        risk = model(X).cpu().item()\n",
        "    return risk\n",
        "\n",
        "def generate_risks(forecast_df):\n",
        "    \"\"\"Predict risk for multiple locations and return DataFrame with risks.\"\"\"\n",
        "    risks = []\n",
        "    for idx, row in forecast_df.iterrows():\n",
        "        r = predict_risk_row(row)\n",
        "        risks.append(r)\n",
        "    forecast_df['risk'] = risks\n",
        "    return forecast_df"
      ],
      "metadata": {
        "id": "VCSV3TewYuxw"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# HEATMAP FUNCTION\n",
        "# ==============================================================#\n",
        "def generate_heatmap(data, output_html=None):\n",
        "    \"\"\"Creates a folium heatmap from DataFrame with columns ['latitude','longitude','risk'].\"\"\"\n",
        "    if output_html is None:\n",
        "        output_html = os.path.join(MODEL_DIR, \"wildfire_heatmap.html\")\n",
        "    center = [data['latitude'].mean(), data['longitude'].mean()]\n",
        "    m = folium.Map(location=center, zoom_start=6)\n",
        "    heat_data = data[['latitude','longitude','risk']].values.tolist()\n",
        "    HeatMap(heat_data, radius=15, blur=20, max_zoom=10).add_to(m)\n",
        "    m.save(output_html)\n",
        "    print(\"✅ Heatmap saved to:\", output_html)"
      ],
      "metadata": {
        "id": "4_4MfQT9ZP10"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================#\n",
        "# EXAMPLE USAGE\n",
        "# ==============================================================#\n",
        "if __name__ == \"__main__\":\n",
        "    # Forecasted weather for 48 hours ahead for multiple locations\n",
        "    forecast_data = pd.DataFrame({\n",
        "        'latitude':[34.52, 35.12, 34.85],\n",
        "        'longitude':[-118.25, -118.50, -118.10],\n",
        "        'acq_date':[datetime.now() + timedelta(hours=48)]*3,\n",
        "        'avgtemp_c':[32, 30, 33],\n",
        "        'total_precip_mm':[0, 1, 0.5],\n",
        "        'avg_humidity':[40, 50, 35],\n",
        "        'pressure_in':[29.9, 29.8, 29.7],\n",
        "        'wind_kph':[15, 10, 20]\n",
        "    })\n",
        "\n",
        "    # Generate predicted risks\n",
        "    forecast_data = generate_risks(forecast_data)\n",
        "    print(\"🔥 Predicted 48-hour risks:\\n\", forecast_data[['latitude','longitude','risk']])\n",
        "\n",
        "    # Generate Folium heatmap HTML\n",
        "    heatmap_path = os.path.join(MODEL_DIR, \"wildfire_heatmap_48h.html\")\n",
        "    generate_heatmap(forecast_data, output_html=heatmap_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quY36JQNaAz4",
        "outputId": "1c83c24d-515c-4aca-d5b6-8934a49f55db"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔥 Predicted 48-hour risks:\n",
            "    latitude  longitude      risk\n",
            "0     34.52    -118.25  0.544749\n",
            "1     35.12    -118.50  0.477413\n",
            "2     34.85    -118.10  0.601462\n",
            "✅ Heatmap saved to: /content/drive/MyDrive/Colab Notebooks/result/wildfire_heatmap_48h.html\n"
          ]
        }
      ]
    }
  ]
}